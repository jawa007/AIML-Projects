# Artificial Intelligence and Machine Learning Projects
Projects completed as a part of Great Learning's PGP - Artificial Intelligence and Machine Learning. The program is internationally recognized and participants earn dual certificates from The University of Texas at Austin and Great Lakes.
## Projects done
1. Statistical Learning
    - This module covered - Descriptive Statistics, - Probability & Conditional Probability, - Hypothesis Testing, - Inferential Statistics, - Probability Distributions, - Types of distribution and - Binomial, Poisson & Normal distribution
    - **Project link:** [Applied Stats](https://nbviewer.jupyter.org/github/sharmapratik88/AIML-Projects/blob/master/01_Applied%20Stats/Medical%20Cost%20Dataset.ipynb)
        - This project used Hypothesis Testing and Visualization to leverage customer's health information like smoking habits, bmi, age, and gender for checking statistical evidence to make valuable decisions of insurance business like charges for health insurance.
    
2. Supervised Machine Learning
    - This module covered - Multiple Variable Linear regression, - Logistic regression, - Naive Bayes classifiers, - Multiple regression, - K-NN classification, - Support vector machines
    - **Project link:** [Supervised Machine Learning](https://nbviewer.jupyter.org/github/sharmapratik88/AIML-Projects/blob/master/02_Supervised%20Machine%20Learning/02_Supervised%20Machine%20Learning.ipynb)
        - Identified potential loan customers for Thera Bank using classification techniques. Compared models built with Logistic Regression and KNN algorithm in order to select the best performing one.

3. Ensemble Techniques
    - This module covered - Decision Trees, - Bagging, - Random Forests, - Boosting
    - **Project link:** [Ensemble Technique](https://nbviewer.jupyter.org/github/sharmapratik88/AIML-Projects/blob/master/03_Ensemble%20Techniques/03_Ensemble%20Techniques.ipynb)
        - Leveraged customer information of bank marketing campaigns to predict whether a customer will subscribe to term deposit or not. Different classification algorithms like Decision tree, Logistic Regression were used. Ensemble techniques like Random forest were used to further improve the classification results.

4. Unsupervised Machine Learning
    - This module covered - K-means clustering, - High-dimensional clustering, - Hierarchical clustering, - Dimension Reduction-PCA
    - **Project link:** [Unsupervised Learning](https://nbviewer.jupyter.org/github/sharmapratik88/AIML-Projects/blob/master/04_Unsupervised%20Learning/04_Unsupervised%20Learning.ipynb)
        - Classified vehicles into different types based on silhouettes which may be viewed from many angles. Used PCA in order to reduce dimensionality and SVM for classification

5. Feature Engineering Techniques
    - This module covered - Exploratory data analysis, - Building ML models for regression, - Hyperparameter tuning
    - **Project link:** [Feature Engineering Technique](https://nbviewer.jupyter.org/github/sharmapratik88/AIML-Projects/blob/master/05_Feature%20Engineering%20Techniques/05_Feature_Engineering_Techniques.ipynb)
         - This project involved feature exploration and selection to predict the strength of high-performance concrete. Used Regression models like Decision tree regressors to find out the most important features and predict the strength. Cross-validation techniques and Grid search were used to tune the parameters for best model performance.
    
6. Recommendation Systems
    - This module covered - Introduction to Recommendation systems, - Popularity based model, - Hybrid models, - Content based recommendation system, - Collaborative filtering (User similarity & Item similarity)
    - **Project link:**
    
7. Neural Network Basics
    - This module covered - Gradient Descent, - Batch Normalization, - Hyper parameter tuning, - Tensor Flow & Keras for Neural Networks & Deep Learning, - Introduction to Perceptron & Neural Networks, - Activation and Loss functions, - Deep Neural Networks
    - **Project link:**

8. Computer Vision
    - This module covered - Introduction to Convolutional Neural Networks, - Convolution, Pooling, Padding & its mechanisms, - Transfer Learning, - Forward propagation & Backpropagation for CNNs, - CNN architectures like AlexNet, VGGNet, InceptionNet & ResNet
    - **Project link:**
    
9. Statistical NLP (Natural Language Processing)
    - This module covered - Bag of Words Model, - POS Tagging, - Tokenization, - Word Vectorizer, - TF-IDF, - Named Entity Recognition, - Stop Words
    - **Project link:**
    
10. Sequential NLP (Natural Language Processing)
    - This module covered - Introduction to Sequential data, - Vanishing & Exploding gradients in RNNs, - LSTMs, - GRUs (Gated recurrent unit), - Case study: Sentiment analysis, - RNNs and its mechanisms, - Time series analysis, - LSTMs with attention mechanism, - Case study: Machine Translation
    - **Project link:**
    
11. Advanced Computer Vision
    - This module covered - Semantic segmentation, - Siamese Networks, - YOLO, - Object & face recognition using techniques above
    - **Project link:**
    
12. GANs (Generative adversarial networks)
    - This module covered - Introduction to GANs, - How GANs work?, - AutoEncoders, - Applications of GANs
    - **Project link:**
    
13. Reinforcement Learning
    - This module covered - Value based methods Q-learning, - Policy based methods
    - **Project link:**
